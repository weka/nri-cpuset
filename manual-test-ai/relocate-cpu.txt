# CPU Live Reallocation Test - Multi-Node DaemonSet Validation

Validates integer pod live reallocation functionality per PRD sections 3.1 and 3.2 across all cluster nodes:
- Integer pods must be reallocated when annotated pods create CPU conflicts
- Annotated pods receive exact CPUs specified in weka.io/cores-ids annotation
- Reallocation maintains sibling core preference for optimal performance
- Test validates behavior consistently across all nodes in parallel

## Prerequisites
- KUBECONFIG set to cluster with NRI-enabled containerd
- Weka NRI CPUSet plugin deployed and running
- Multi-core nodes available for testing
- `xargs`, `grep`, `awk` utilities available

## Test Steps

### 1. Environment Setup
```bash
kubectl create namespace manual-tests --dry-run=client -o yaml | kubectl apply -f -

# Get list of worker nodes for validation
kubectl get nodes --no-headers -o custom-columns="NAME:.metadata.name" | grep -v master | head -10 > /tmp/test-nodes.txt
echo "Testing on $(wc -l < /tmp/test-nodes.txt) nodes"
```

### 2. Deploy Integer DaemonSet (Exclusive CPU Request)
Create DaemonSet with integer CPU requirements across all nodes:
```yaml
# integer-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: integer-test-ds
  namespace: manual-tests
spec:
  selector:
    matchLabels:
      app: integer-test
  template:
    metadata:
      labels:
        app: integer-test
    spec:
      containers:
      - name: test-container
        image: busybox:latest
        command: ["sleep", "600"]
        resources:
          requests:
            cpu: "2"        # Integer value
            memory: "512Mi"
          limits:
            cpu: "2"        # Must equal requests for integer classification  
            memory: "512Mi" # Must equal requests for integer classification
      restartPolicy: Always
      nodeSelector:
        node-role.kubernetes.io/worker: "true"  # Target worker nodes only
```

**Expected**: Plugin allocates 2 exclusive CPUs per node with sibling core preference

### 3. Verify Initial CPU Assignments Across All Nodes
```bash
kubectl apply -f integer-daemonset.yaml
kubectl rollout status daemonset/integer-test-ds -n manual-tests --timeout=120s

# Bulk verify CPU assignments across all nodes
echo "=== Initial Integer Pod CPU Assignments ==="
kubectl get pods -n manual-tests -l app=integer-test -o wide --no-headers | \
  awk '{print $1 " " $7}' | \
  xargs -I {} -P 10 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); cpus=$(kubectl exec -n manual-tests $pod -- cat /proc/1/status 2>/dev/null | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]"); echo "$node: $pod -> CPUs: $cpus"'
```

**Expected Output**: Each node shows integer pod with 2 exclusive CPUs (sibling cores preferred)

### 4. Create Dynamic Annotated DaemonSet
Generate annotated DaemonSet that conflicts with integer pods using discovered CPU assignments:
```bash
# Extract CPU assignments and create conflicting annotations
kubectl get pods -n manual-tests -l app=integer-test -o wide --no-headers | \
  awk '{print $1 " " $7}' | \
  xargs -I {} -P 10 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); cpus=$(kubectl exec -n manual-tests $pod -- cat /proc/1/status 2>/dev/null | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]"); echo "$node=$cpus"' > /tmp/node-cpu-map.txt

# Create annotated DaemonSet template
cat > annotated-daemonset.yaml << 'EOF'
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: annotated-test-ds
  namespace: manual-tests
spec:
  selector:
    matchLabels:
      app: annotated-test
  template:
    metadata:
      labels:
        app: annotated-test
      annotations:
        weka.io/cores-ids: "PLACEHOLDER_CPUS"
    spec:
      containers:
      - name: test-container
        image: busybox:latest
        command: ["sleep", "600"]
        resources:
          requests:
            cpu: "100m"     # Fractional (non-integer) to ensure shared classification
            memory: "128Mi"
          limits:
            cpu: "200m"     # Different from requests to ensure shared classification
            memory: "256Mi"
      restartPolicy: Always
      nodeSelector:
        node-role.kubernetes.io/worker: "true"
EOF

# Deploy annotated DaemonSet (will initially conflict with integer pods)
# Note: This creates a single DaemonSet - real conflict resolution happens per-node
# We'll use a common CPU range that likely conflicts on most nodes
kubectl get pods -n manual-tests -l app=integer-test --no-headers | head -1 | \
  xargs -I {} sh -c 'cpus=$(kubectl exec -n manual-tests {} -- cat /proc/1/status | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]"); sed "s/PLACEHOLDER_CPUS/$cpus/" annotated-daemonset.yaml' | \
  kubectl apply -f -
```

**Expected**: Plugin detects conflicts and triggers live reallocation per node

### 5. Verify Live Reallocation Results Across All Nodes
```bash
kubectl rollout status daemonset/annotated-test-ds -n manual-tests --timeout=120s

# Bulk verification of final CPU assignments
echo "=== Post-Reallocation CPU Assignments ==="
echo "Annotated Pods (should have exact requested CPUs):"
kubectl get pods -n manual-tests -l app=annotated-test -o wide --no-headers | \
  awk '{print $1 " " $7}' | \
  xargs -I {} -P 10 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); cpus=$(kubectl exec -n manual-tests $pod -- cat /proc/1/status 2>/dev/null | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]"); echo "$node: $pod -> CPUs: $cpus"'

echo ""
echo "Integer Pods (should be reallocated to different CPUs):"
kubectl get pods -n manual-tests -l app=integer-test -o wide --no-headers | \
  awk '{print $1 " " $7}' | \
  xargs -I {} -P 10 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); cpus=$(kubectl exec -n manual-tests $pod -- cat /proc/1/status 2>/dev/null | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]"); echo "$node: $pod -> CPUs: $cpus"'

# Validate no CPU overlaps between pod types
echo ""
echo "=== CPU Overlap Validation ==="
kubectl get pods -n manual-tests -o wide --no-headers | \
  awk '{print $1 " " $6 " " $7}' | \
  xargs -I {} -P 10 sh -c 'pod=$(echo {} | cut -d" " -f1); label=$(echo {} | cut -d" " -f2); node=$(echo {} | cut -d" " -f3); cpus=$(kubectl exec -n manual-tests $pod -- cat /proc/1/status 2>/dev/null | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]"); echo "$node:$label:$cpus"' | \
  sort | \
  awk -F: 'BEGIN{print "Checking for CPU conflicts by node..."} {node=$1; type=$2; cpus=$3; if(node==prev_node && cpus==prev_cpus && type!=prev_type) print "CONFLICT: Node " node " has overlapping CPUs " cpus " between " prev_type " and " type; prev_node=node; prev_type=type; prev_cpus=cpus}'
```

### 6. Verify Plugin Logs Across All Nodes
```bash
echo "=== Plugin Conflict Resolution Logs ==="
# Check logs from all plugin instances for conflict detection
kubectl get pods -n kube-system -l app=weka-nri-cpuset --no-headers -o custom-columns="NAME:.metadata.name,NODE:.spec.nodeName" | \
  xargs -I {} -P 5 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); logs=$(kubectl logs -n kube-system $pod --since=3m 2>/dev/null | grep -E "(Conflicts detected|Found.*conflicting|Executing reallocation|Generated.*updates)" | head -5); if [ ! -z "$logs" ]; then echo "=== $node ($pod) ==="; echo "$logs"; echo ""; fi'

# Summary of reallocation activity
echo "=== Reallocation Summary ==="
kubectl logs -n kube-system -l app=weka-nri-cpuset --since=3m 2>/dev/null | \
  grep -c "Conflicts detected" | \
  xargs -I {} echo "Total conflict events detected: {}"

kubectl logs -n kube-system -l app=weka-nri-cpuset --since=3m 2>/dev/null | \
  grep -c "Generated.*container updates" | \
  xargs -I {} echo "Total reallocation operations: {}"
```

### 7. Validate Sibling Core Preference
```bash
echo "=== Sibling Core Analysis ==="
# Check if reallocated CPUs maintain sibling relationships
kubectl get pods -n manual-tests -l app=integer-test -o wide --no-headers | \
  awk '{print $1 " " $7}' | \
  xargs -I {} -P 10 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); cpus=$(kubectl exec -n manual-tests $pod -- cat /proc/1/status 2>/dev/null | grep Cpus_allowed_list | cut -d":" -f2 | tr -d "[:space:]" | tr "," " "); echo "$node: $cpus"' | \
  while IFS=': ' read -r node cpu1 cpu2; do
    if [ ! -z "$cpu2" ]; then
      # Check if CPUs are siblings by examining topology
      kubectl get nodes $node -o jsonpath='{.status.capacity.cpu}' >/dev/null 2>&1 && \
      echo "$node: CPU pair $cpu1,$cpu2 (sibling check requires node topology access)"
    fi
  done
```

## Success Criteria

1. **Multi-Node Validation**: Test executes successfully on all worker nodes
2. **Conflict Detection**: Plugin identifies CPU overlaps on each node with conflicts  
3. **Atomic Reallocation**: Integer pods move to new exclusive CPUs without interruption across all nodes
4. **Annotation Compliance**: Annotated pods receive exactly requested CPUs from weka.io/cores-ids on all nodes
5. **No CPU Overlaps**: Post-reallocation verification shows no shared CPUs between pod types
6. **Sibling Core Preference**: Reallocated CPUs maintain hyperthread pairing when possible
7. **Consistent Behavior**: Reallocation logic works identically across different node configurations

## Bulk Operations & Performance

### Efficient Multi-Node Queries:
- **Parallel execution**: `xargs -P` for concurrent operations across nodes
- **Bulk data collection**: Single queries with batch processing via `awk`
- **Pattern matching**: `grep -E` with multiple patterns for log analysis
- **Data aggregation**: Pipeline operations for summary statistics

### Query Optimization Examples:
```bash
# Get all pod CPU assignments in one operation
kubectl get pods -n manual-tests -o wide --no-headers | \
  awk '{print $1 " " $7}' | \
  xargs -I {} -P 20 sh -c 'pod=$(echo {} | cut -d" " -f1); node=$(echo {} | cut -d" " -f2); kubectl exec -n manual-tests $pod -- cat /proc/1/status | grep Cpus_allowed_list | sed "s/^/$node: $pod: /"'

# Aggregate plugin logs from all nodes
kubectl logs -n kube-system -l app=weka-nri-cpuset --since=5m | \
  grep -E "(Conflicts|reallocation|Generated)" | \
  sort | uniq -c | sort -nr
```

## Troubleshooting

### Common Issues:
- **DaemonSet scheduling failures**: Check node selectors and resource availability
- **Bulk operation timeouts**: Reduce parallelism (`-P` value) or increase timeouts
- **Plugin instability**: Monitor plugin restart counts across nodes
- **CPU assignment variations**: Different nodes may have different CPU topologies

### Debugging Commands:
```bash
# Check DaemonSet rollout status
kubectl get daemonset -n manual-tests -o wide

# Monitor plugin health across all nodes
kubectl get pods -n kube-system -l app=weka-nri-cpuset -o wide

# Bulk log collection for analysis
kubectl logs -n kube-system -l app=weka-nri-cpuset --since=10m > /tmp/all-plugin-logs.txt

# Node resource availability check
kubectl top nodes | head -10
```

## Cleanup
```bash
kubectl delete namespace manual-tests
rm -f /tmp/test-nodes.txt /tmp/node-cpu-map.txt /tmp/all-plugin-logs.txt
rm -f integer-daemonset.yaml annotated-daemonset.yaml
```

## Test Validation

This test confirms PRD compliance for:
- Section 3.1: Annotated pod admission with conflict resolution (multi-node)
- Section 3.2: Runtime updates and live reassignment (cluster-wide)  
- Section 3.5: Sibling core preference strategy (consistent across nodes)
- Section 4: Atomic transaction semantics (per-node validation)
- Scalability: Bulk validation methods for large cluster testing
